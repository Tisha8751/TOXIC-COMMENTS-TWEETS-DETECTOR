# TOXIC-COMMENTS-TWEETS-DETECTOR
Toxic comment is a public speech that expresses hate or encourages violence towards a person or group based on race, religion, sex or sexual orientation, country, caste, and creed. Hate speech in any form of communication may it be verbal, written, or gesture-based on various aspects such as race, color, gender, disability, citizenship, and religion which is used to provoke unpleasant feelings in an individual or group of individuals that may incite violence, self-harm or any harm to the public in general. To implement a toxic comment classifier, we will make use of natural language processing, text analysis, and computational linguistics to systematically identify the toxic comments/tweets on Twitter. Our model takes in the comments/tweets as input and lets us know in which category the comment/tweets lie. 
